{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data만 tensorflow를 이용해 load -> numpy 객체로 받아옴\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_layers(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, n_neurons):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(input_size, n_neurons), nn.ReLU()]\n",
    "        for _ in range(n_hidden-1):\n",
    "            layers.append(nn.Linear(n_neurons,n_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(n_neurons, 10))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        # if len(x.shape) == 3:\n",
    "        #     x = x.unsqueeze(1)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝이기 때문에 CV를 사용하지 않고, hold out을 사용\n",
    "from sklearn.model_selection import RandomizedSearchCV, PredefinedSplit\n",
    "\n",
    "# hold out instead of cross-validation\n",
    "valid_idx = [-1]*X_train.shape[0] +[0]*X_valid.shape[0]\n",
    "X_train_valid = np.concatenate([X_train, X_valid])\n",
    "y_train_valid = np.concatenate([y_train, y_valid])\n",
    "ps = PredefinedSplit(valid_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "param_random = {\n",
    "    'module__n_hidden':stats.randint(0,8+1),\n",
    "    'module__n_neurons':stats.randint(16,256+1),\n",
    "    'lr':stats.loguniform(1e-4, 1e-2),\n",
    "    'optimizer':[torch.optim.SGD, torch.optim.Adam]\n",
    "}\n",
    "net = NeuralNetClassifier(MLP_layers,\n",
    "                            module__input_size = 28*28,\n",
    "                            module__n_hidden=2,\n",
    "                            module__n_neurons=16,\n",
    "                            max_epochs = 10,\n",
    "                            lr = 1e-2,\n",
    "                            optimizer = torch.optim.SGD,\n",
    "                            criterion = nn.CrossEntropyLoss,\n",
    "                            device = 'cuda',\n",
    "                            train_split=None,\n",
    "                            verbose=0\n",
    "                            )\n",
    "rand = RandomizedSearchCV(net, param_random, cv=ps, n_jobs=-1, n_iter=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.MLP_layers'>,\n",
       "  module__input_size=784,\n",
       "  module__n_hidden=2,\n",
       "  module__n_neurons=16,\n",
       "),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'lr': <scipy.stats._distn_infrastructure.rv_continuous_frozen object at 0x7f443307bee0>,\n",
       "                                        'module__n_hidden': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f443307bc10>,\n",
       "                                        'module__n_neurons': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7f443307bf40>,\n",
       "                                        'optimizer': [<class 'torch.optim.sgd.SGD'>,\n",
       "                                                      <class 'torch.optim.adam.Adam'>]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = RandomizedSearchCV(net, param_random, cv=ps, n_jobs=-1, n_iter=15)\n",
    "rand.fit(torch.Tensor(X_train_valid), torch.Tensor(y_train_valid).type(torch.LongTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_module__n_hidden</th>\n",
       "      <th>param_module__n_neurons</th>\n",
       "      <th>param_optimizer</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.077406</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.8772</td>\n",
       "      <td>0.8772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.965037</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.068388</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>3</td>\n",
       "      <td>236</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.8688</td>\n",
       "      <td>0.8688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28.239262</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>4</td>\n",
       "      <td>253</td>\n",
       "      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.8660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>28.242951</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>6</td>\n",
       "      <td>145</td>\n",
       "      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>0.8638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  param_lr param_module__n_hidden param_module__n_neurons  \\\n",
       "8       31.077406  0.000217                      6                     155   \n",
       "3       27.965037  0.001078                      4                      38   \n",
       "5       28.068388  0.002493                      3                     236   \n",
       "13      28.239262  0.002234                      4                     253   \n",
       "14      28.242951  0.002857                      6                     145   \n",
       "\n",
       "                    param_optimizer  split0_test_score  mean_test_score  \n",
       "8   <class 'torch.optim.adam.Adam'>             0.8772           0.8772  \n",
       "3   <class 'torch.optim.adam.Adam'>             0.8698           0.8698  \n",
       "5   <class 'torch.optim.adam.Adam'>             0.8688           0.8688  \n",
       "13  <class 'torch.optim.adam.Adam'>             0.8660           0.8660  \n",
       "14    <class 'torch.optim.sgd.SGD'>             0.8638           0.8638  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(rand.cv_results_).sort_values(by='split0_test_score',ascending=False)[['mean_fit_time',\n",
    "'param_lr','param_module__n_hidden','param_module__n_neurons','param_optimizer','split0_test_score','mean_test_score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('choi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f1ea343d18a0e98dbd50f4a3341f5f39bd7be7d912eea72d8401c1237c2e901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
