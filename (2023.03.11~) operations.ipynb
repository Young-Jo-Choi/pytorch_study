{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# einsum\n",
    "torch.einsum(equation, *operands)<br>\n",
    "공식홈페이지 : Sums the product of the elements of the input operands along dimensions specified using a notation based on the Einstein summation convention.\n",
    "\n",
    "numpy, tensorflow에도 동일한 연산이 있음\n",
    "\n",
    "equation은 inputs->output이며 각 tensor의 shape을 나타냄, inputs는 \",\"를 통해 여러 개를 구분함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(equation,  *matrix, input_print=True):\n",
    "    if input_print:\n",
    "        print('Before operating')\n",
    "        for mat in matrix:\n",
    "            print(mat)\n",
    "    einsum = torch.einsum(equation, *matrix)\n",
    "    print('After operating')\n",
    "    print(einsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before operating\n",
      "tensor([[ 5, 13,  5],\n",
      "        [ 6, 14, 15]], dtype=torch.int32)\n",
      "After operating\n",
      "tensor(58)\n",
      "After operating\n",
      "tensor([23, 35])\n",
      "After operating\n",
      "tensor([11, 27, 20])\n"
     ]
    }
   ],
   "source": [
    "# 1개의 tensor에 대한 sum\n",
    "test = (torch.rand(2,3)*20).int()\n",
    "check('ij->', test)\n",
    "# 행의 개수를 유지한채 반환되도록 행별로 더함\n",
    "check('ij->i', test, input_print=False)\n",
    "# 열의 개수를 유지한채 반환되로독 열별로 더함\n",
    "check('ij->j', test, input_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before operating\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([0., 1., 2.])\n",
      "After operating\n",
      "tensor([[ 0.,  1.,  4.],\n",
      "        [ 0.,  4., 10.]])\n",
      "After operating\n",
      "tensor([ 5., 14.])\n",
      "Before operating\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([[0., 3.],\n",
      "        [1., 4.],\n",
      "        [2., 5.]])\n",
      "After operating\n",
      "tensor([[ 5., 14.],\n",
      "        [14., 50.]])\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 tensor에 대한 \n",
    "test1 = torch.Tensor([[0,1,2],[3,4,5]])\n",
    "test2 = torch.Tensor([0,1,2])\n",
    "check('ij, j->ij', test1, test2, input_print=True)\n",
    "check('ij, j->i', test1, test2, input_print=False)\n",
    "check('ik,kj->ij', test1, test1.T, input_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat & repeat_interleave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- repeat은 어느 dimension으로 반복시킬지 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "dim=0으로 2번, dim=1로 3번\n",
      " tensor([[1., 2., 3., 1., 2., 3., 1., 2., 3.],\n",
      "        [4., 5., 6., 4., 5., 6., 4., 5., 6.],\n",
      "        [1., 2., 3., 1., 2., 3., 1., 2., 3.],\n",
      "        [4., 5., 6., 4., 5., 6., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "print('\\ndim=0으로 2번, dim=1로 3번\\n',x.repeat(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- repeat_interleave는 element 하나하나를 반복시킴\n",
    "- 차원별로 repeat의 횟수를 다르게 설정할 수 있음\n",
    "- 어느 차원으로 repeat할지 설정 가능\n",
    "- repeats 인자는 Tensor or int, dim 인자는 int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "dim=0으로 2번 반복 : \n",
      " tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "dim=1으로 2번 반복 : \n",
      " tensor([[1., 1., 2., 2., 3., 3.],\n",
      "        [4., 4., 5., 5., 6., 6.]])\n",
      "\n",
      "dim=1으로 2번 반복 : \n",
      " tensor([[1., 1., 2., 2., 3., 3.],\n",
      "        [4., 4., 5., 5., 6., 6.]])\n",
      "\n",
      "dim=0로 x의 행에 대해서는 2번, x의 열에 대해서는 3번 반복\n",
      " tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [4., 5., 6.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([[1,2,3],[4,5,6]])\n",
    "print(x)\n",
    "print('\\ndim=0으로 2번 반복 : \\n' ,x.repeat_interleave(2, dim=0))\n",
    "print('\\ndim=1으로 2번 반복 : \\n' ,x.repeat_interleave(2, dim=1))\n",
    "print('\\ndim=1으로 2번 반복 : \\n' ,x.repeat_interleave(2, dim=1))\n",
    "print('\\ndim=0로 x의 행에 대해서는 2번, x의 열에 대해서는 3번 반복\\n',x.repeat_interleave(repeats=torch.tensor([2,3]), dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution filter\n",
    "filter는 output개수 * 3차원 모양<br>\n",
    "각 channel에 대해 다음과 같이 연산됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape : torch.Size([3, 32, 32]), output shape : torch.Size([6, 29, 29]), filter shape : torch.Size([6, 3, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "temp = torch.randn(3,32,32)\n",
    "conv = nn.Conv2d(3, 6, kernel_size=(4,4), bias=False)\n",
    "temp2 = conv(temp)\n",
    "print(f'input shape : {temp.shape}, output shape : {temp2.shape}, filter shape : {conv.weight.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7445, -1.3043, -0.7599],\n",
      "        [-0.0114,  1.1250, -0.2401],\n",
      "        [ 0.2970,  0.9768,  0.1136]], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.7445, -1.3043, -0.7599],\n",
      "        [-0.0114,  1.1250, -0.2401],\n",
      "        [ 0.2970,  0.9768,  0.1136]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a,b,c = conv.weight[0,0], conv.weight[0,1], conv.weight[0,2]\n",
    "aa = F.conv2d(temp[0].unsqueeze(0), a.unsqueeze(0).unsqueeze(0))\n",
    "bb = F.conv2d(temp[1].unsqueeze(0), b.unsqueeze(0).unsqueeze(0))\n",
    "cc = F.conv2d(temp[2].unsqueeze(0), c.unsqueeze(0).unsqueeze(0))\n",
    "\n",
    "print((aa+bb+cc)[0,:3,:3])\n",
    "print(temp2[0,:3,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('choi_torch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25532f8c11ced9521f0a8f8b016926f91b16d0cc9b0f549b50762a497f4b71fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
