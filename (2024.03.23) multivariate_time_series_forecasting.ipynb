{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- 시계열 데이터에 대한 예측\n",
        "    - HEPC(house hold electric power consumption) dataset : 다변량 시계열 데이터\n",
        "- tensorflow로 모델 개발\n",
        "- torch로 동일한 모델 개발"
      ],
      "metadata": {
        "id": "2aY0-oXABdCT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HEPC dataset\n",
        "모든 컬럼에 대한 forecasting을 수행"
      ],
      "metadata": {
        "id": "1TnVMPFCKAxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/household_power.zip'\n",
        "urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "hepc = pd.read_csv('household_power_consumption.csv')\n",
        "print(hepc.shape)\n",
        "hepc.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "bbFNf7wOHZQW",
        "outputId": "ea365efb-2bec-45f8-c244-c3b2b1a32bf9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86400, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              datetime  Global_active_power  Global_reactive_power  Voltage  \\\n",
              "0  2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
              "1  2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
              "2  2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
              "3  2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
              "4  2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
              "\n",
              "   Global_intensity  Sub_metering_1  Sub_metering_2  Sub_metering_3  \n",
              "0              18.4             0.0             1.0            17.0  \n",
              "1              23.0             0.0             1.0            16.0  \n",
              "2              23.0             0.0             2.0            17.0  \n",
              "3              23.0             0.0             1.0            17.0  \n",
              "4              15.8             0.0             1.0            17.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cbb4e80-b0a3-4de7-b511-34aebcd2b78d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>datetime</th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-12-16 17:24:00</td>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-12-16 17:25:00</td>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-12-16 17:26:00</td>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-12-16 17:27:00</td>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-12-16 17:28:00</td>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cbb4e80-b0a3-4de7-b511-34aebcd2b78d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7cbb4e80-b0a3-4de7-b511-34aebcd2b78d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7cbb4e80-b0a3-4de7-b511-34aebcd2b78d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aad3cfff-05c0-4a67-bf62-b373d16646bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aad3cfff-05c0-4a67-bf62-b373d16646bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aad3cfff-05c0-4a67-bf62-b373d16646bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "hepc",
              "summary": "{\n  \"name\": \"hepc\",\n  \"rows\": 86400,\n  \"fields\": [\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 86400,\n        \"samples\": [\n          \"2007-01-15 20:48:00\",\n          \"2007-02-09 02:41:00\",\n          \"2006-12-20 23:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_active_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.335541718985206,\n        \"min\": 0.194,\n        \"max\": 9.272,\n        \"num_unique_values\": 3347,\n        \"samples\": [\n          5.406,\n          5.626,\n          3.904\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_reactive_power\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1176214630431444,\n        \"min\": 0.0,\n        \"max\": 0.874,\n        \"num_unique_values\": 377,\n        \"samples\": [\n          0.656,\n          0.466,\n          0.632\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Voltage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.498535931183726,\n        \"min\": 224.68,\n        \"max\": 251.7,\n        \"num_unique_values\": 2174,\n        \"samples\": [\n          238.73,\n          248.19,\n          237.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Global_intensity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.629462938587408,\n        \"min\": 0.8,\n        \"max\": 40.4,\n        \"num_unique_values\": 189,\n        \"samples\": [\n          37.4,\n          36.2,\n          13.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.682567482882876,\n        \"min\": 0.0,\n        \"max\": 77.0,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          0.0,\n          36.0,\n          14.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.5676794757081645,\n        \"min\": 0.0,\n        \"max\": 78.0,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          37.0,\n          40.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sub_metering_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.67190930406459,\n        \"min\": 0.0,\n        \"max\": 20.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          17.0,\n          12.0,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "data_origin = hepc.values[:,1:]\n",
        "data = data_origin.astype('float32')\n",
        "data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
        "n_features = data.shape[1]\n"
      ],
      "metadata": {
        "id": "J9gWDpphJhUH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train, valid split\n",
        "train_size = int(len(data) * 0.5)\n",
        "train_data, valid_data = data[:train_size, :], data[train_size:, :]"
      ],
      "metadata": {
        "id": "7EQFPl1N2fT7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tensorflow"
      ],
      "metadata": {
        "id": "w-_BaK1dJ-U1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size= (n_past + n_future),shift = shift, drop_remainder = True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    ds = ds.map(\n",
        "        lambda w: (w[:n_past], w[n_past:])\n",
        "    )\n",
        "    return ds.batch(batch_size).prefetch(1)"
      ],
      "metadata": {
        "id": "ixpIsPXBJhQw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "# 0~23의 데이터를 이용해 뒤의 24~47의 데이터를 예측함\n",
        "n_past = 24\n",
        "n_future = 24\n",
        "batch_size = 32\n",
        "# window_size = n_past + n_future\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(51)\n",
        "np.random.seed(51)\n",
        "\n",
        "train_set = windowed_dataset(train_data, batch_size, n_past, n_future)\n",
        "valid_set = windowed_dataset(valid_data, batch_size, n_past, n_future)"
      ],
      "metadata": {
        "id": "4YTwiN9RJhOT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,(x_tf,y_tf) in enumerate(train_set.take(1)):\n",
        "    if i==1:\n",
        "        break"
      ],
      "metadata": {
        "id": "nxbMTUmoOvgQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tf.shape, y_tf.shape"
      ],
      "metadata": {
        "id": "ePrZOY1-PAOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f4234df-ddd3-4130-aa71-ebcb2f6e9c8c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 24, 7]), TensorShape([32, 24, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first batch\n",
        "x_tf[0,:10,0], y_tf[0,:10,0]"
      ],
      "metadata": {
        "id": "CVg4FMf5SsNI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da248fdc-66b2-44d2-d1dc-552089577a44"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([0.44304916, 0.56906813, 0.5706103 , 0.5721525 , 0.38246307,\n",
              "        0.36638024, 0.3864287 , 0.38620842, 0.3826834 , 0.38202247],\n",
              "       dtype=float32)>,\n",
              " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              " array([0.47146946, 0.3364177 , 0.33509585, 0.33421457, 0.33751926,\n",
              "        0.32870677, 0.27825513, 0.39259747, 0.45692882, 0.4756554 ],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:10,0], train_data[n_past:n_past+10,0]"
      ],
      "metadata": {
        "id": "RXbFXMImTvbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcf3b09-14eb-4f7f-9498-c8f6d61fd6c7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.44304916, 0.56906813, 0.5706103 , 0.5721525 , 0.38246307,\n",
              "        0.36638024, 0.3864287 , 0.38620842, 0.3826834 , 0.38202247],\n",
              "       dtype=float32),\n",
              " array([0.47146946, 0.3364177 , 0.33509585, 0.33421457, 0.33751926,\n",
              "        0.32870677, 0.27825513, 0.39259747, 0.45692882, 0.4756554 ],\n",
              "       dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def equal_two_tensor(a,b):\n",
        "    aa,_ = tf.unique(tf.reshape(a==b,-1))\n",
        "    return aa.numpy()\n",
        "equal_two_tensor(y_tf[0,:,:],train_data[n_past:n_past+n_future, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVcIPgMd9Y6W",
        "outputId": "e608549a-4aba-4eca-910e-0d06394b6eb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고\n",
        "print(x_tf.shape)\n",
        "x_conv_tf = keras.layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', input_shape=[n_past, n_features])(x_tf)\n",
        "print(x_conv_tf.shape)\n",
        "# Bidrectional은 양방향으로 학습할 수 있게 함\n",
        "x_lstm1_tf = Bidirectional(keras.layers.LSTM(64, return_sequences=True))(x_conv_tf)\n",
        "print(x_lstm1_tf.shape)\n",
        "x_lstm2_tf = Bidirectional(keras.layers.LSTM(64, return_sequences=True))(x_lstm1_tf)\n",
        "print(x_lstm2_tf.shape)\n",
        "x_dense1_tf = keras.layers.Dense(32, activation='relu')(x_lstm2_tf)\n",
        "print(x_dense1_tf.shape)\n",
        "\n",
        "# (32,24,128)은 batch size : 32, sequence_length (n_past) : 24, feature의 개수 64*2 를 의미함"
      ],
      "metadata": {
        "id": "hYHn33zAo4MZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a69178-daf7-4be8-aa0e-fc42d3f6135a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 24, 7)\n",
            "(32, 24, 32)\n",
            "(32, 24, 128)\n",
            "(32, 24, 128)\n",
            "(32, 24, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    # causal padding은 시계열 데이터에서 미래의 데이터를 미리 보는 일을 방지하기 위해 과거 데이터쪽으로만 padding을 추가\n",
        "    keras.layers.Conv1D(filters=32, kernel_size=3, padding='causal', activation='relu', input_shape=[n_past, n_features]),\n",
        "    Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
        "    Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(n_features)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
        "model.compile(loss='mae', optimizer=optimizer, metrics=['mae'])\n",
        "\n",
        "# callback은 생략\n",
        "model.fit(train_set, epochs=20, validation_data=valid_set)"
      ],
      "metadata": {
        "id": "RH7M8i7SJhLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9064ae1d-1464-40f9-db0e-a984734755f3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1349/1349 [==============================] - 34s 19ms/step - loss: 0.0968 - mae: 0.0968 - val_loss: 0.0720 - val_mae: 0.0720\n",
            "Epoch 2/20\n",
            "1349/1349 [==============================] - 24s 18ms/step - loss: 0.0704 - mae: 0.0704 - val_loss: 0.0653 - val_mae: 0.0653\n",
            "Epoch 3/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0633 - mae: 0.0633 - val_loss: 0.0637 - val_mae: 0.0637\n",
            "Epoch 4/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0608 - mae: 0.0608 - val_loss: 0.0625 - val_mae: 0.0625\n",
            "Epoch 5/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0592 - mae: 0.0592 - val_loss: 0.0588 - val_mae: 0.0588\n",
            "Epoch 6/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0577 - mae: 0.0577 - val_loss: 0.0597 - val_mae: 0.0597\n",
            "Epoch 7/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0568 - mae: 0.0568 - val_loss: 0.0575 - val_mae: 0.0575\n",
            "Epoch 8/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0557 - mae: 0.0557 - val_loss: 0.0571 - val_mae: 0.0571\n",
            "Epoch 9/20\n",
            "1349/1349 [==============================] - 22s 17ms/step - loss: 0.0552 - mae: 0.0552 - val_loss: 0.0578 - val_mae: 0.0578\n",
            "Epoch 10/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0543 - mae: 0.0543 - val_loss: 0.0574 - val_mae: 0.0574\n",
            "Epoch 11/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0541 - mae: 0.0541 - val_loss: 0.0554 - val_mae: 0.0554\n",
            "Epoch 12/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0530 - mae: 0.0530 - val_loss: 0.0537 - val_mae: 0.0537\n",
            "Epoch 13/20\n",
            "1349/1349 [==============================] - 22s 16ms/step - loss: 0.0527 - mae: 0.0527 - val_loss: 0.0539 - val_mae: 0.0539\n",
            "Epoch 14/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0523 - mae: 0.0523 - val_loss: 0.0531 - val_mae: 0.0531\n",
            "Epoch 15/20\n",
            "1349/1349 [==============================] - 22s 17ms/step - loss: 0.0520 - mae: 0.0520 - val_loss: 0.0527 - val_mae: 0.0527\n",
            "Epoch 16/20\n",
            "1349/1349 [==============================] - 22s 16ms/step - loss: 0.0515 - mae: 0.0515 - val_loss: 0.0524 - val_mae: 0.0524\n",
            "Epoch 17/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0510 - mae: 0.0510 - val_loss: 0.0521 - val_mae: 0.0521\n",
            "Epoch 18/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0513 - mae: 0.0513 - val_loss: 0.0517 - val_mae: 0.0517\n",
            "Epoch 19/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0504 - mae: 0.0504 - val_loss: 0.0514 - val_mae: 0.0514\n",
            "Epoch 20/20\n",
            "1349/1349 [==============================] - 23s 17ms/step - loss: 0.0505 - mae: 0.0505 - val_loss: 0.0517 - val_mae: 0.0517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f308b922b60>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_mae = 0\n",
        "i = 100\n",
        "count = 0\n",
        "y_mean_list = []\n",
        "y_pred_mean_list = []\n",
        "for x, y in valid_set.take(i):\n",
        "    y_pred = model(x)\n",
        "    y_mean_list.append(y.numpy().mean())\n",
        "    y_pred_mean_list.append(y_pred.numpy().mean())\n",
        "    mae = np.mean(np.abs(y.numpy() - y_pred.numpy()))\n",
        "    total_mae += mae\n",
        "    count += 1\n",
        "total_mae /= count\n",
        "print(y_mean_list[:15])\n",
        "print(y_pred_mean_list[:15])\n",
        "print(total_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23OEBno02FOo",
        "outputId": "8530a163-a67a-4dfe-c384-a42e5025a28d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.2860595, 0.25557086, 0.2915365, 0.33576047, 0.30199873, 0.24839891, 0.15883857, 0.14882076, 0.18442619, 0.22276969, 0.26605153, 0.16713813, 0.13072902, 0.122702315, 0.10736147]\n",
            "[0.28207186, 0.2843352, 0.25927487, 0.31562564, 0.2935661, 0.29329696, 0.16311651, 0.1436135, 0.15680802, 0.16621979, 0.20332561, 0.17216176, 0.13226289, 0.1275591, 0.116526276]\n",
            "0.05357529351487756\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# pytorch"
      ],
      "metadata": {
        "id": "OTLk2Of0UawY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, series, n_past, n_future):\n",
        "        self.series = series\n",
        "        self.n_past = n_past\n",
        "        self.n_future = n_future\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.series.shape[0] - self.n_past - self.n_future\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.series[idx : idx+self.n_past, :]\n",
        "        y = self.series[idx+self.n_past : idx+self.n_past+self.n_future, :]\n",
        "        return X, y\n",
        "\n",
        "n_past = 24\n",
        "n_future = 24\n",
        "timeSeries_DS = TimeSeriesDataset(train_data, n_past, n_future)\n",
        "x_torch, y_torch = timeSeries_DS[0]"
      ],
      "metadata": {
        "id": "6SBWQxWFUce4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeSeries_loader = DataLoader(timeSeries_DS, batch_size=32, shuffle=True)\n",
        "x_torch,y_torch = next(iter(timeSeries_loader))\n",
        "x_torch.shape, y_torch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SizrGx_iYTQ",
        "outputId": "a0dbf829-e092-44c3-e6ce-09af9ab4b619"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 24, 7]), torch.Size([32, 24, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# causal padding을 지원하는 conv1d 층 구현\n",
        "class CausalConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, **kwargs):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, **kwargs)\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # kernel_size - 1 만큼 패딩을 오른쪽(미래 데이터 측)에 추가\n",
        "        # input : (batch, channel, sequence)\n",
        "        padding = (0,self.kernel_size - 1,0,0)\n",
        "        # pad has the form (padding_left,padding_right,padding_top,padding_bottom)\n",
        "        x = F.pad(x, pad=padding, mode='constant')  # 'constant'는 0으로 패딩한다는 의미\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "NjeNa6lkgIoo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고\n",
        "F.pad(x_torch, pad=(0,0,0,4), mode='constant').shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z76jRB0ZmE5R",
        "outputId": "ae058e35-d348-45a4-9985-f89eb87933f9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 28, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고\n",
        "print(x_torch.shape)\n",
        "print(x_torch.permute(0,2,1).shape)\n",
        "temp = CausalConv1d(in_channels=7, out_channels=32, kernel_size=3)\n",
        "x_conv_torch = temp(x_torch.permute(0,2,1).float())\n",
        "print(x_conv_torch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtDk4tcBgvM0",
        "outputId": "61566a29-8740-4aeb-ca4b-a82827cb0e3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 24, 7])\n",
            "torch.Size([32, 7, 24])\n",
            "torch.Size([32, 32, 24])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 참고\n",
        "# Note: batch_first=True makes the input and output tensors of shape (batch, seq, feature)\n",
        "print(x_conv_torch.permute(0,2,1).shape)\n",
        "x_lstm1_torch, _ = nn.LSTM(input_size=32, hidden_size=64, batch_first=True, bidirectional=True)(x_conv_torch.permute(0,2,1))\n",
        "print(x_lstm1_torch.shape)\n",
        "x_lstm2_torch, _ = nn.LSTM(input_size=64, hidden_size=64, batch_first=True, bidirectional=True)(x_lstm1_torch)\n",
        "print(x_lstm2_torch.shape)\n",
        "x_dense1_torch = nn.Linear(in_features=64*2, out_features=32)(x_lstm2_torch)\n",
        "print(x_dense1_torch.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_dhyAxpoDmu",
        "outputId": "3f319253-da33-49db-d3a7-4015800661d4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 24, 32])\n",
            "torch.Size([32, 24, 128])\n",
            "torch.Size([32, 24, 128])\n",
            "torch.Size([32, 24, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.debugger import set_trace"
      ],
      "metadata": {
        "id": "poHMvpzipMdn"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class timeSeriesModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1d = CausalConv1d(in_channels=7, out_channels=32, kernel_size=3)\n",
        "\n",
        "        # Note: batch_first=True makes the input and output tensors of shape (batch, seq, feature)\n",
        "        self.lstm1 = nn.LSTM(input_size=32, hidden_size=64, batch_first=True, bidirectional=True)\n",
        "        self.lstm2 = nn.LSTM(input_size=64*2, hidden_size=64, batch_first=True, bidirectional=True)\n",
        "        self.dense1 = nn.Linear(in_features=64*2, out_features=32)\n",
        "        self.dense2 = nn.Linear(in_features=32, out_features=16)\n",
        "        self.dense3 = nn.Linear(in_features=16, out_features=7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim()==2:\n",
        "            # channel\n",
        "            x = x.unsqueeze(1)\n",
        "        x = x.permute(0,2,1)\n",
        "        x = torch.relu(self.conv1d(x.float()))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x, _ = self.lstm1(x)\n",
        "        x, _ = self.lstm2(x)\n",
        "        x = torch.relu(self.dense1(x))\n",
        "        x = torch.relu(self.dense2(x))\n",
        "        x = self.dense3(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "MexBptPNYwHI"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeSeries_model = timeSeriesModel()\n",
        "x_final = timeSeries_model(x_torch)\n",
        "x_final.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFOuuQDHqBYm",
        "outputId": "77bddf1c-d834-461b-930a-29992727b73e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 24, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timeSeries_model = timeSeriesModel()\n",
        "x_final = timeSeries_model(x_torch)\n",
        "x_final.shape"
      ],
      "metadata": {
        "id": "ypxRVhGwZFBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0d064e1-83db-452b-eb95-7ed20a6929f9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 24, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_DS = TimeSeriesDataset(train_data, n_past, n_future)\n",
        "train_loader = DataLoader(train_DS, batch_size=32, shuffle=True)\n",
        "val_DS = TimeSeriesDataset(valid_data, n_past, n_future)\n",
        "val_loader = DataLoader(val_DS, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "P6MRnxXYw5Le"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timeSeries_model = timeSeriesModel()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "timeSeries_model.to(device)\n",
        "optimizer = torch.optim.Adam(timeSeries_model.parameters(), lr=0.0005)\n",
        "criterion = nn.L1Loss().to(device)"
      ],
      "metadata": {
        "id": "H75RjSv9ZYX5"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 40\n",
        "for epoch in range(epochs):\n",
        "    train_loss = 0\n",
        "    train_mae = 0\n",
        "    timeSeries_model.train()\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs = inputs.float().to(device)\n",
        "        targets = targets.float().to(device)\n",
        "        outputs = timeSeries_model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss +=  loss.item() * inputs.size(0)\n",
        "        train_mae += torch.mean(torch.abs(targets - outputs)) * inputs.size(0)\n",
        "    train_loss /= len(train_DS)\n",
        "    train_mae /= len(train_DS)\n",
        "\n",
        "\n",
        "    val_loss = 0\n",
        "    val_mae = 0\n",
        "    timeSeries_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in val_loader:\n",
        "            inputs = inputs.float().to(device)\n",
        "            targets = targets.float().to(device)\n",
        "            outputs = timeSeries_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_mae += torch.mean(torch.abs(targets - outputs)) * inputs.size(0)\n",
        "    val_loss /= len(val_DS)\n",
        "    val_mae /= len(val_DS)\n",
        "\n",
        "    print(f'''Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.6f}, Train MAE: {train_mae:.6f}, Val Loss: {val_loss:.6f}, Val MAE: {val_mae:.6f}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw5F7f4jZYVr",
        "outputId": "ce34cfd1-4998-488d-d3ee-2426346d0306"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40, Train Loss: 0.068534, Train MAE: 0.068534, Val Loss: 0.053746, Val MAE: 0.053746\n",
            "Epoch 2/40, Train Loss: 0.051068, Train MAE: 0.051068, Val Loss: 0.051627, Val MAE: 0.051627\n",
            "Epoch 3/40, Train Loss: 0.049924, Train MAE: 0.049924, Val Loss: 0.050810, Val MAE: 0.050810\n",
            "Epoch 4/40, Train Loss: 0.050078, Train MAE: 0.050078, Val Loss: 0.049938, Val MAE: 0.049938\n",
            "Epoch 5/40, Train Loss: 0.050079, Train MAE: 0.050079, Val Loss: 0.050146, Val MAE: 0.050145\n",
            "Epoch 6/40, Train Loss: 0.048486, Train MAE: 0.048486, Val Loss: 0.049966, Val MAE: 0.049966\n",
            "Epoch 7/40, Train Loss: 0.048086, Train MAE: 0.048086, Val Loss: 0.049805, Val MAE: 0.049805\n",
            "Epoch 8/40, Train Loss: 0.047039, Train MAE: 0.047039, Val Loss: 0.049179, Val MAE: 0.049179\n",
            "Epoch 9/40, Train Loss: 0.045717, Train MAE: 0.045717, Val Loss: 0.047152, Val MAE: 0.047152\n",
            "Epoch 10/40, Train Loss: 0.044981, Train MAE: 0.044981, Val Loss: 0.047378, Val MAE: 0.047378\n",
            "Epoch 11/40, Train Loss: 0.044450, Train MAE: 0.044450, Val Loss: 0.047158, Val MAE: 0.047158\n",
            "Epoch 12/40, Train Loss: 0.043960, Train MAE: 0.043960, Val Loss: 0.046559, Val MAE: 0.046559\n",
            "Epoch 13/40, Train Loss: 0.043735, Train MAE: 0.043735, Val Loss: 0.046080, Val MAE: 0.046080\n",
            "Epoch 14/40, Train Loss: 0.043284, Train MAE: 0.043284, Val Loss: 0.046539, Val MAE: 0.046539\n",
            "Epoch 15/40, Train Loss: 0.042971, Train MAE: 0.042971, Val Loss: 0.045975, Val MAE: 0.045975\n",
            "Epoch 16/40, Train Loss: 0.042766, Train MAE: 0.042766, Val Loss: 0.045953, Val MAE: 0.045953\n",
            "Epoch 17/40, Train Loss: 0.042374, Train MAE: 0.042374, Val Loss: 0.046174, Val MAE: 0.046174\n",
            "Epoch 18/40, Train Loss: 0.042029, Train MAE: 0.042029, Val Loss: 0.045936, Val MAE: 0.045936\n",
            "Epoch 19/40, Train Loss: 0.041679, Train MAE: 0.041679, Val Loss: 0.045977, Val MAE: 0.045977\n",
            "Epoch 20/40, Train Loss: 0.041456, Train MAE: 0.041457, Val Loss: 0.046228, Val MAE: 0.046228\n",
            "Epoch 21/40, Train Loss: 0.041204, Train MAE: 0.041204, Val Loss: 0.045935, Val MAE: 0.045935\n",
            "Epoch 22/40, Train Loss: 0.040786, Train MAE: 0.040786, Val Loss: 0.046103, Val MAE: 0.046103\n",
            "Epoch 23/40, Train Loss: 0.040456, Train MAE: 0.040456, Val Loss: 0.046424, Val MAE: 0.046424\n",
            "Epoch 24/40, Train Loss: 0.040283, Train MAE: 0.040283, Val Loss: 0.046290, Val MAE: 0.046290\n",
            "Epoch 25/40, Train Loss: 0.039818, Train MAE: 0.039818, Val Loss: 0.046265, Val MAE: 0.046265\n",
            "Epoch 26/40, Train Loss: 0.039587, Train MAE: 0.039587, Val Loss: 0.046820, Val MAE: 0.046820\n",
            "Epoch 27/40, Train Loss: 0.039166, Train MAE: 0.039166, Val Loss: 0.046472, Val MAE: 0.046472\n",
            "Epoch 28/40, Train Loss: 0.038896, Train MAE: 0.038896, Val Loss: 0.046464, Val MAE: 0.046464\n",
            "Epoch 29/40, Train Loss: 0.038622, Train MAE: 0.038622, Val Loss: 0.046637, Val MAE: 0.046637\n",
            "Epoch 30/40, Train Loss: 0.038247, Train MAE: 0.038247, Val Loss: 0.046705, Val MAE: 0.046705\n",
            "Epoch 31/40, Train Loss: 0.038065, Train MAE: 0.038065, Val Loss: 0.046984, Val MAE: 0.046984\n",
            "Epoch 32/40, Train Loss: 0.037584, Train MAE: 0.037584, Val Loss: 0.047241, Val MAE: 0.047241\n",
            "Epoch 33/40, Train Loss: 0.037156, Train MAE: 0.037156, Val Loss: 0.048114, Val MAE: 0.048114\n",
            "Epoch 34/40, Train Loss: 0.036835, Train MAE: 0.036835, Val Loss: 0.048058, Val MAE: 0.048058\n",
            "Epoch 35/40, Train Loss: 0.036507, Train MAE: 0.036507, Val Loss: 0.047803, Val MAE: 0.047803\n",
            "Epoch 36/40, Train Loss: 0.036234, Train MAE: 0.036234, Val Loss: 0.047693, Val MAE: 0.047693\n",
            "Epoch 37/40, Train Loss: 0.036405, Train MAE: 0.036405, Val Loss: 0.047580, Val MAE: 0.047580\n",
            "Epoch 38/40, Train Loss: 0.035897, Train MAE: 0.035897, Val Loss: 0.047660, Val MAE: 0.047660\n",
            "Epoch 39/40, Train Loss: 0.035329, Train MAE: 0.035329, Val Loss: 0.048546, Val MAE: 0.048546\n",
            "Epoch 40/40, Train Loss: 0.035127, Train MAE: 0.035127, Val Loss: 0.048280, Val MAE: 0.048280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_mae = 0\n",
        "counts = 0\n",
        "target_mean_list = []\n",
        "output_mean_list = []\n",
        "for inputs, targets in val_loader:\n",
        "    inputs = inputs.float().to(device)\n",
        "    targets = targets.float().to(device)\n",
        "    outputs = timeSeries_model(inputs).squeeze()\n",
        "    target_mean_list.append(targets.detach().cpu().numpy().mean())\n",
        "    output_mean_list.append(outputs.detach().cpu().numpy().mean())\n",
        "    mae = np.mean(np.abs(targets.cpu().detach().numpy() - outputs.detach().cpu().numpy()))\n",
        "    total_mae += mae\n",
        "    counts += 1\n",
        "total_mae /= counts\n",
        "print(target_mean_list[:15])\n",
        "print(output_mean_list[:15])\n",
        "print(total_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4VDBoKi4IBX",
        "outputId": "72e11e51-794d-41e6-a09a-a289c36a40c0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.19166344, 0.19137448, 0.20841342, 0.17906198, 0.21587715, 0.2104038, 0.20672266, 0.19373319, 0.23610584, 0.19015433, 0.20844854, 0.21148664, 0.20723788, 0.21822807, 0.22518626]\n",
            "[0.19274715, 0.18033658, 0.21612795, 0.18819961, 0.20976031, 0.19615929, 0.20551637, 0.19172361, 0.215268, 0.19013861, 0.19882125, 0.20873438, 0.19238204, 0.2173624, 0.19911987]\n",
            "0.048282099157306684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWFM8b6Pdu_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}