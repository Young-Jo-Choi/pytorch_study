{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from source import cifar_dataloader\n",
    "path = './../data/'\n",
    "loader_dict = cifar_dataloader.get_cifar100_dataloader(path = path, batch_size=128)\n",
    "train_loader = loader_dict['train']\n",
    "val_loader = loader_dict['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 500\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# supervised-contrastive learning\n",
    "- 사전학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "loader_dict = cifar_dataloader.get_cifar100_dataloader(path = path, batch_size=256)\n",
    "train_loader = loader_dict['train']\n",
    "val_loader = loader_dict['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(model.conv1, model.bn1, model.relu, model.maxpool,\n",
    "                     model.layer1, model.layer2, model.layer3, model.layer4, model.avgpool)\n",
    "\n",
    "classifier = nn.Sequential(nn.Flatten(), model.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = encoder(x[:32].to(device))\n",
    "xx = F.normalize(classifier(xx), dim=1)\n",
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrastive learning phase\n",
    "# https://github.com/HobbitLong/SupContrast/blob/master/losses.py\n",
    "\n",
    "from source.SupConLoss import SupConLoss\n",
    "criterion = SupConLoss(temperature=0.07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "split_with_sizes expects split_sizes to sum exactly to 32 (input tensor's size at dimension 0), but got split_sizes=[32, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m yy \u001b[39m=\u001b[39m y[:\u001b[39m32\u001b[39m]\n\u001b[1;32m      2\u001b[0m bsz \u001b[39m=\u001b[39m yy\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m f1,f2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49msplit(xx, [bsz, bsz], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/choi/lib/python3.8/site-packages/torch/functional.py:189\u001b[0m, in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    184\u001b[0m         split, (tensor,), tensor, split_size_or_sections, dim\u001b[39m=\u001b[39mdim)\n\u001b[1;32m    185\u001b[0m \u001b[39m# Overwriting reason:\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[39m# This dispatches to two ATen functions depending on the type of\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[39m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m# call here.\u001b[39;00m\n\u001b[0;32m--> 189\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39;49msplit(split_size_or_sections, dim)\n",
      "File \u001b[0;32m~/.conda/envs/choi/lib/python3.8/site-packages/torch/_tensor.py:803\u001b[0m, in \u001b[0;36mTensor.split\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_VF\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m, split_size, dim)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    802\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 803\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_VF\u001b[39m.\u001b[39;49msplit_with_sizes(\u001b[39mself\u001b[39;49m, split_size, dim)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: split_with_sizes expects split_sizes to sum exactly to 32 (input tensor's size at dimension 0), but got split_sizes=[32, 32]"
     ]
    }
   ],
   "source": [
    "yy = y[:32]\n",
    "bsz = yy.shape[0]\n",
    "f1,f2 = torch.split(xx, [bsz, bsz], dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
