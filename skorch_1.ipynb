{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN housing example\n",
    "SGD 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras에서 불러오는 데이터의 train test index는 다를 수 있음\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_targets, test_targets = train_test_split(df.values[:,:-1], df.values[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## original tensorflow codes\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(64, activation='relu', kernel_initializer='glorot_uniform',input_shape=(train_data.shape[1],)))\n",
    "# model.add(layers.Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "# model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class MLP_Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1=64, hidden_size2=64, output_size=1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, output_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.initialize = torch.nn.init.xavier_uniform_\n",
    "\n",
    "        self.initialize(self.fc1.weight.data)\n",
    "        self.initialize(self.fc2.weight.data)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_size = train_data.shape[1]\n",
    "model = MLP_Net(input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x_tensor, y_tensor):\n",
    "        super().__init__()\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "        \n",
    "train_data = torch.Tensor(train_data)\n",
    "train_targets = torch.Tensor(train_targets)\n",
    "test_data = torch.Tensor(test_data)\n",
    "test_targets = torch.Tensor(test_targets)\n",
    "train_dataset = CustomDataset(train_data, train_targets)\n",
    "test_dataset = CustomDataset(test_data, test_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "epochs = 80\n",
    "# 다른 optimizer 사용 가능\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, nesterov=True)\n",
    "# optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "# criterion = F.mse_loss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/80, train_loss = 506.4531\n",
      "Epoch: 1/80, train_loss = 86.5718\n",
      "Epoch: 2/80, train_loss = 27.6986\n",
      "Epoch: 3/80, train_loss = 17.9663\n",
      "Epoch: 4/80, train_loss = 15.8619\n",
      "Epoch: 5/80, train_loss = 13.8324\n",
      "Epoch: 6/80, train_loss = 11.9657\n",
      "Epoch: 7/80, train_loss = 11.7827\n",
      "Epoch: 8/80, train_loss = 12.1598\n",
      "Epoch: 9/80, train_loss = 10.1205\n",
      "Epoch: 10/80, train_loss = 9.5888\n",
      "Epoch: 11/80, train_loss = 9.2459\n",
      "Epoch: 12/80, train_loss = 9.5615\n",
      "Epoch: 13/80, train_loss = 8.4899\n",
      "Epoch: 14/80, train_loss = 8.4303\n",
      "Epoch: 15/80, train_loss = 8.3829\n",
      "Epoch: 16/80, train_loss = 7.9714\n",
      "Epoch: 17/80, train_loss = 7.7313\n",
      "Epoch: 18/80, train_loss = 7.5618\n",
      "Epoch: 19/80, train_loss = 7.6541\n",
      "Epoch: 20/80, train_loss = 7.2659\n",
      "Epoch: 21/80, train_loss = 6.8254\n",
      "Epoch: 22/80, train_loss = 7.2568\n",
      "Epoch: 23/80, train_loss = 6.8550\n",
      "Epoch: 24/80, train_loss = 6.5442\n",
      "Epoch: 25/80, train_loss = 6.6454\n",
      "Epoch: 26/80, train_loss = 6.7458\n",
      "Epoch: 27/80, train_loss = 6.2386\n",
      "Epoch: 28/80, train_loss = 6.2327\n",
      "Epoch: 29/80, train_loss = 6.0157\n",
      "Epoch: 30/80, train_loss = 5.9603\n",
      "Epoch: 31/80, train_loss = 5.8648\n",
      "Epoch: 32/80, train_loss = 5.9380\n",
      "Epoch: 33/80, train_loss = 5.9324\n",
      "Epoch: 34/80, train_loss = 5.6411\n",
      "Epoch: 35/80, train_loss = 5.5213\n",
      "Epoch: 36/80, train_loss = 5.7730\n",
      "Epoch: 37/80, train_loss = 5.4847\n",
      "Epoch: 38/80, train_loss = 5.3229\n",
      "Epoch: 39/80, train_loss = 5.2688\n",
      "Epoch: 40/80, train_loss = 5.0813\n",
      "Epoch: 41/80, train_loss = 5.2910\n",
      "Epoch: 42/80, train_loss = 5.0059\n",
      "Epoch: 43/80, train_loss = 4.7895\n",
      "Epoch: 44/80, train_loss = 4.7621\n",
      "Epoch: 45/80, train_loss = 4.7119\n",
      "Epoch: 46/80, train_loss = 5.1556\n",
      "Epoch: 47/80, train_loss = 4.5628\n",
      "Epoch: 48/80, train_loss = 4.7169\n",
      "Epoch: 49/80, train_loss = 4.7880\n",
      "Epoch: 50/80, train_loss = 4.2648\n",
      "Epoch: 51/80, train_loss = 4.2982\n",
      "Epoch: 52/80, train_loss = 4.3248\n",
      "Epoch: 53/80, train_loss = 4.1694\n",
      "Epoch: 54/80, train_loss = 4.3223\n",
      "Epoch: 55/80, train_loss = 4.0912\n",
      "Epoch: 56/80, train_loss = 4.5948\n",
      "Epoch: 57/80, train_loss = 4.1872\n",
      "Epoch: 58/80, train_loss = 4.0733\n",
      "Epoch: 59/80, train_loss = 4.2014\n",
      "Epoch: 60/80, train_loss = 4.1314\n",
      "Epoch: 61/80, train_loss = 3.8193\n",
      "Epoch: 62/80, train_loss = 4.0248\n",
      "Epoch: 63/80, train_loss = 3.7011\n",
      "Epoch: 64/80, train_loss = 3.8543\n",
      "Epoch: 65/80, train_loss = 3.4990\n",
      "Epoch: 66/80, train_loss = 3.3635\n",
      "Epoch: 67/80, train_loss = 4.0325\n",
      "Epoch: 68/80, train_loss = 3.6517\n",
      "Epoch: 69/80, train_loss = 3.4969\n",
      "Epoch: 70/80, train_loss = 3.6811\n",
      "Epoch: 71/80, train_loss = 3.5404\n",
      "Epoch: 72/80, train_loss = 4.3150\n",
      "Epoch: 73/80, train_loss = 3.3981\n",
      "Epoch: 74/80, train_loss = 3.4270\n",
      "Epoch: 75/80, train_loss = 3.6856\n",
      "Epoch: 76/80, train_loss = 3.3538\n",
      "Epoch: 77/80, train_loss = 3.3901\n",
      "Epoch: 78/80, train_loss = 3.3003\n",
      "Epoch: 79/80, train_loss = 3.4641\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "# losses = []\n",
    "for epoch in range(epochs):\n",
    "    train_losses = 0\n",
    "    data_count = 0\n",
    "    for i,(inputs, targets) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, targets.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        data_count += len(targets)\n",
    "        # losses.append(loss.item())\n",
    "        train_losses += (loss.item() * len(targets))\n",
    "    train_losses /= data_count\n",
    "    print(f'Epoch: {epoch}/{epochs}, train_loss = {train_losses:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "targets_list = []\n",
    "outputs_list = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        targets = targets.detach().cpu().numpy()\n",
    "        outputs = outputs.detach().cpu().numpy()\n",
    "        targets_list.append(targets)\n",
    "        outputs_list.append(outputs)\n",
    "        # sgd.zero_grad()\n",
    "        # loss.backward()\n",
    "        # sgd.step()\n",
    "        # data_count += inputs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.177858318591625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "mse(np.concatenate(targets_list), np.concatenate(outputs_list))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단 skorch를 써서 모델 돌려보면 keras만큼 편리한 API 사용가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    MLP_Net(input_size=input_size),\n",
    "    max_epochs=80,\n",
    "    lr=0.001,\n",
    "    device=device,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    batch_size = 64,\n",
    "    train_split=None  # no validation set split -> fully train on train set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m493.7890\u001b[0m  0.0162\n",
      "      2       \u001b[36m72.2849\u001b[0m  0.0163\n",
      "      3       \u001b[36m24.3399\u001b[0m  0.0172\n",
      "      4       \u001b[36m18.3379\u001b[0m  0.0174\n",
      "      5       \u001b[36m14.6024\u001b[0m  0.0176\n",
      "      6       \u001b[36m12.8560\u001b[0m  0.0247\n",
      "      7       \u001b[36m12.1223\u001b[0m  0.0209\n",
      "      8       \u001b[36m11.2419\u001b[0m  0.0189\n",
      "      9       \u001b[36m10.5558\u001b[0m  0.0178\n",
      "     10       \u001b[36m10.0890\u001b[0m  0.0176\n",
      "     11        \u001b[36m9.7039\u001b[0m  0.0171\n",
      "     12        \u001b[36m9.2995\u001b[0m  0.0171\n",
      "     13        \u001b[36m9.0077\u001b[0m  0.0163\n",
      "     14        \u001b[36m8.6788\u001b[0m  0.0232\n",
      "     15        \u001b[36m8.3675\u001b[0m  0.0120\n",
      "     16        \u001b[36m8.0916\u001b[0m  0.0133\n",
      "     17        \u001b[36m7.8517\u001b[0m  0.0135\n",
      "     18        \u001b[36m7.5930\u001b[0m  0.0144\n",
      "     19        \u001b[36m7.3824\u001b[0m  0.0149\n",
      "     20        \u001b[36m7.1630\u001b[0m  0.0148\n",
      "     21        \u001b[36m6.9772\u001b[0m  0.0145\n",
      "     22        \u001b[36m6.7895\u001b[0m  0.0144\n",
      "     23        \u001b[36m6.6485\u001b[0m  0.0148\n",
      "     24        \u001b[36m6.4882\u001b[0m  0.0159\n",
      "     25        \u001b[36m6.3049\u001b[0m  0.0163\n",
      "     26        \u001b[36m6.1581\u001b[0m  0.0174\n",
      "     27        \u001b[36m6.0036\u001b[0m  0.0174\n",
      "     28        \u001b[36m5.8556\u001b[0m  0.0177\n",
      "     29        \u001b[36m5.7259\u001b[0m  0.0178\n",
      "     30        \u001b[36m5.5922\u001b[0m  0.0181\n",
      "     31        \u001b[36m5.4823\u001b[0m  0.0177\n",
      "     32        \u001b[36m5.3843\u001b[0m  0.0179\n",
      "     33        \u001b[36m5.2456\u001b[0m  0.0174\n",
      "     34        \u001b[36m5.1284\u001b[0m  0.0177\n",
      "     35        \u001b[36m5.0387\u001b[0m  0.0179\n",
      "     36        \u001b[36m4.9316\u001b[0m  0.0163\n",
      "     37        \u001b[36m4.8132\u001b[0m  0.0170\n",
      "     38        \u001b[36m4.7094\u001b[0m  0.0174\n",
      "     39        \u001b[36m4.6140\u001b[0m  0.0183\n",
      "     40        \u001b[36m4.5103\u001b[0m  0.0182\n",
      "     41        \u001b[36m4.4419\u001b[0m  0.0179\n",
      "     42        \u001b[36m4.3336\u001b[0m  0.0182\n",
      "     43        \u001b[36m4.2655\u001b[0m  0.0157\n",
      "     44        \u001b[36m4.2008\u001b[0m  0.0169\n",
      "     45        \u001b[36m4.1410\u001b[0m  0.0176\n",
      "     46        \u001b[36m4.0696\u001b[0m  0.0175\n",
      "     47        \u001b[36m4.0122\u001b[0m  0.0179\n",
      "     48        \u001b[36m3.9431\u001b[0m  0.0181\n",
      "     49        \u001b[36m3.8795\u001b[0m  0.0184\n",
      "     50        \u001b[36m3.8283\u001b[0m  0.0180\n",
      "     51        \u001b[36m3.7632\u001b[0m  0.0179\n",
      "     52        \u001b[36m3.7060\u001b[0m  0.0173\n",
      "     53        \u001b[36m3.6564\u001b[0m  0.0171\n",
      "     54        \u001b[36m3.6026\u001b[0m  0.0184\n",
      "     55        \u001b[36m3.5652\u001b[0m  0.0223\n",
      "     56        \u001b[36m3.5034\u001b[0m  0.0194\n",
      "     57        \u001b[36m3.4512\u001b[0m  0.0178\n",
      "     58        \u001b[36m3.4046\u001b[0m  0.0164\n",
      "     59        \u001b[36m3.3563\u001b[0m  0.0165\n",
      "     60        \u001b[36m3.3067\u001b[0m  0.0171\n",
      "     61        \u001b[36m3.2704\u001b[0m  0.0172\n",
      "     62        \u001b[36m3.2240\u001b[0m  0.0169\n",
      "     63        \u001b[36m3.1884\u001b[0m  0.0160\n",
      "     64        \u001b[36m3.1492\u001b[0m  0.0227\n",
      "     65        \u001b[36m3.1149\u001b[0m  0.0212\n",
      "     66        \u001b[36m3.0748\u001b[0m  0.0183\n",
      "     67        \u001b[36m3.0544\u001b[0m  0.0169\n",
      "     68        \u001b[36m3.0111\u001b[0m  0.0157\n",
      "     69        \u001b[36m2.9853\u001b[0m  0.0154\n",
      "     70        \u001b[36m2.9484\u001b[0m  0.0268\n",
      "     71        \u001b[36m2.9119\u001b[0m  0.0116\n",
      "     72        \u001b[36m2.8902\u001b[0m  0.0128\n",
      "     73        \u001b[36m2.8533\u001b[0m  0.0143\n",
      "     74        \u001b[36m2.8253\u001b[0m  0.0152\n",
      "     75        \u001b[36m2.7930\u001b[0m  0.0150\n",
      "     76        \u001b[36m2.7784\u001b[0m  0.0150\n",
      "     77        \u001b[36m2.7397\u001b[0m  0.0150\n",
      "     78        \u001b[36m2.7083\u001b[0m  0.0148\n",
      "     79        \u001b[36m2.6759\u001b[0m  0.0150\n",
      "     80        \u001b[36m2.6361\u001b[0m  0.0150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=MLP_Net(\n",
       "    (fc1): Linear(in_features=13, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (activation): ReLU()\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataSet으로 넣기 가능(y=None)\n",
    "net.fit(torch.Tensor(train_data), torch.Tensor(train_targets.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.45181884918875"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "pred = net.predict(torch.Tensor(test_data))\n",
    "mse(test_targets, pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss     dur\n",
      "-------  ------------  ------\n",
      "      1      \u001b[36m533.8962\u001b[0m  0.0176\n",
      "      2       \u001b[36m90.1277\u001b[0m  0.0165\n",
      "      3       \u001b[36m27.6133\u001b[0m  0.0166\n",
      "      4       \u001b[36m17.7880\u001b[0m  0.0171\n",
      "      5       \u001b[36m14.6904\u001b[0m  0.0172\n",
      "      6       \u001b[36m12.8080\u001b[0m  0.0284\n",
      "      7       \u001b[36m12.0846\u001b[0m  0.0101\n",
      "      8       \u001b[36m11.1892\u001b[0m  0.0111\n",
      "      9       \u001b[36m10.5502\u001b[0m  0.0126\n",
      "     10       \u001b[36m10.0969\u001b[0m  0.0136\n",
      "     11        \u001b[36m9.7175\u001b[0m  0.0137\n",
      "     12        \u001b[36m9.3291\u001b[0m  0.0140\n",
      "     13        \u001b[36m9.0531\u001b[0m  0.0145\n",
      "     14        \u001b[36m8.7873\u001b[0m  0.0150\n",
      "     15        \u001b[36m8.5502\u001b[0m  0.0147\n",
      "     16        \u001b[36m8.3568\u001b[0m  0.0153\n",
      "     17        \u001b[36m8.0991\u001b[0m  0.0151\n",
      "     18        \u001b[36m7.9316\u001b[0m  0.0154\n",
      "     19        \u001b[36m7.6991\u001b[0m  0.0143\n",
      "     20        \u001b[36m7.5003\u001b[0m  0.0150\n",
      "     21        \u001b[36m7.3385\u001b[0m  0.0150\n",
      "     22        \u001b[36m7.1672\u001b[0m  0.0160\n",
      "     23        \u001b[36m7.0034\u001b[0m  0.0146\n",
      "     24        \u001b[36m6.8821\u001b[0m  0.0149\n",
      "     25        \u001b[36m6.7103\u001b[0m  0.0147\n",
      "     26        \u001b[36m6.6248\u001b[0m  0.0151\n",
      "     27        \u001b[36m6.4927\u001b[0m  0.0154\n",
      "     28        \u001b[36m6.3634\u001b[0m  0.0147\n",
      "     29        \u001b[36m6.2499\u001b[0m  0.0179\n",
      "     30        \u001b[36m6.1482\u001b[0m  0.0244\n",
      "     31        \u001b[36m6.0159\u001b[0m  0.0206\n",
      "     32        \u001b[36m5.9245\u001b[0m  0.0183\n",
      "     33        \u001b[36m5.8170\u001b[0m  0.0182\n",
      "     34        \u001b[36m5.7132\u001b[0m  0.0187\n",
      "     35        \u001b[36m5.5984\u001b[0m  0.0178\n",
      "     36        \u001b[36m5.4951\u001b[0m  0.0324\n",
      "     37        \u001b[36m5.4238\u001b[0m  0.0139\n",
      "     38        \u001b[36m5.3389\u001b[0m  0.0134\n",
      "     39        \u001b[36m5.2503\u001b[0m  0.0144\n",
      "     40        \u001b[36m5.1599\u001b[0m  0.0149\n",
      "     41        \u001b[36m5.0880\u001b[0m  0.0147\n",
      "     42        \u001b[36m5.0009\u001b[0m  0.0151\n",
      "     43        \u001b[36m4.9143\u001b[0m  0.0155\n",
      "     44        \u001b[36m4.8618\u001b[0m  0.0165\n",
      "     45        \u001b[36m4.7950\u001b[0m  0.0164\n",
      "     46        \u001b[36m4.7120\u001b[0m  0.0172\n",
      "     47        \u001b[36m4.6436\u001b[0m  0.0179\n",
      "     48        \u001b[36m4.5687\u001b[0m  0.0181\n",
      "     49        \u001b[36m4.4983\u001b[0m  0.0177\n",
      "     50        \u001b[36m4.4487\u001b[0m  0.0176\n",
      "     51        \u001b[36m4.3892\u001b[0m  0.0174\n",
      "     52        \u001b[36m4.3257\u001b[0m  0.0178\n",
      "     53        \u001b[36m4.2614\u001b[0m  0.0180\n",
      "     54        \u001b[36m4.2178\u001b[0m  0.0179\n",
      "     55        \u001b[36m4.1566\u001b[0m  0.0175\n",
      "     56        \u001b[36m4.1031\u001b[0m  0.0175\n",
      "     57        \u001b[36m4.0644\u001b[0m  0.0176\n",
      "     58        \u001b[36m3.9986\u001b[0m  0.0174\n",
      "     59        \u001b[36m3.9717\u001b[0m  0.0175\n",
      "     60        \u001b[36m3.9141\u001b[0m  0.0167\n",
      "     61        \u001b[36m3.8701\u001b[0m  0.0169\n",
      "     62        \u001b[36m3.8336\u001b[0m  0.0159\n",
      "     63        \u001b[36m3.7731\u001b[0m  0.0169\n",
      "     64        \u001b[36m3.7491\u001b[0m  0.0175\n",
      "     65        \u001b[36m3.6871\u001b[0m  0.0221\n",
      "     66        \u001b[36m3.6449\u001b[0m  0.0106\n",
      "     67        \u001b[36m3.6040\u001b[0m  0.0109\n",
      "     68        \u001b[36m3.5581\u001b[0m  0.0122\n",
      "     69        \u001b[36m3.5277\u001b[0m  0.0142\n",
      "     70        \u001b[36m3.4709\u001b[0m  0.0140\n",
      "     71        \u001b[36m3.4247\u001b[0m  0.0143\n",
      "     72        \u001b[36m3.3812\u001b[0m  0.0141\n",
      "     73        \u001b[36m3.3557\u001b[0m  0.0141\n",
      "     74        \u001b[36m3.3116\u001b[0m  0.0144\n",
      "     75        \u001b[36m3.2859\u001b[0m  0.0142\n",
      "     76        \u001b[36m3.2416\u001b[0m  0.0138\n",
      "     77        \u001b[36m3.2041\u001b[0m  0.0143\n",
      "     78        \u001b[36m3.1750\u001b[0m  0.0141\n",
      "     79        \u001b[36m3.1180\u001b[0m  0.0154\n",
      "     80        \u001b[36m3.0974\u001b[0m  0.0161\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=MLP_Net(\n",
       "    (fc1): Linear(in_features=13, out_features=64, bias=True)\n",
       "    (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (fc3): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (activation): ReLU()\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 혹은 다음과 같이도 가능\n",
    "net = NeuralNetRegressor(\n",
    "    MLP_Net(input_size=input_size),\n",
    "    max_epochs=80,\n",
    "    lr=0.001,\n",
    "    device=device,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    optimizer__momentum=0.9,\n",
    "    optimizer__nesterov=True,\n",
    "    batch_size = 64,\n",
    "    train_split=None  # no validation set split -> fully train on train set\n",
    ")\n",
    "from torch.utils.data import TensorDataset\n",
    "temp = TensorDataset(torch.Tensor(train_data), torch.Tensor(train_targets.reshape(-1, 1)))\n",
    "net.fit(temp, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('choi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f1ea343d18a0e98dbd50f4a3341f5f39bd7be7d912eea72d8401c1237c2e901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
