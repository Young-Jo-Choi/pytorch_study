{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.helper import predefined_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imagenet으로 사전학습된 모델을 cifar100으로 finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms, datasets\n",
    "def get_cifar100_DS(path, input_size=224):\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5071, 0.4867, 0.4408], [0.2675, 0.2565, 0.2761])\n",
    "        ]),\n",
    "    }\n",
    "    imagenet_data_train = datasets.CIFAR100(path, train=True, download=True, transform=data_transforms['train'])\n",
    "    imagenet_data_val = datasets.CIFAR100(path, train=False, download=True, transform=data_transforms['val'])\n",
    "\n",
    "    dataset_dict = {\n",
    "    'train' : imagenet_data_train,\n",
    "    'val' : imagenet_data_val\n",
    "    }\n",
    "    return dataset_dict\n",
    "\n",
    "cifar100_dict = get_cifar100_DS(path='./../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full-finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choiyj/.conda/envs/choi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(weights=models.ResNet18_Weights)\n",
    "resnet.fc = nn.Linear(512, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m2.7961\u001b[0m       \u001b[32m0.4760\u001b[0m        \u001b[35m1.9346\u001b[0m  116.4469\n",
      "      2        \u001b[36m2.1125\u001b[0m       \u001b[32m0.5311\u001b[0m        \u001b[35m1.7282\u001b[0m  116.4275\n",
      "      3        \u001b[36m1.8879\u001b[0m       \u001b[32m0.5876\u001b[0m        \u001b[35m1.4504\u001b[0m  116.3372\n",
      "      4        \u001b[36m1.7301\u001b[0m       \u001b[32m0.6175\u001b[0m        \u001b[35m1.3658\u001b[0m  116.4313\n",
      "      5        \u001b[36m1.6119\u001b[0m       \u001b[32m0.6388\u001b[0m        \u001b[35m1.2496\u001b[0m  116.5739\n",
      "      6        \u001b[36m1.5231\u001b[0m       \u001b[32m0.6484\u001b[0m        1.2669  116.7009\n",
      "      7        \u001b[36m1.4475\u001b[0m       \u001b[32m0.6591\u001b[0m        \u001b[35m1.2176\u001b[0m  116.3685\n",
      "      8        \u001b[36m1.3881\u001b[0m       \u001b[32m0.6772\u001b[0m        \u001b[35m1.1492\u001b[0m  116.3395\n",
      "      9        \u001b[36m1.3249\u001b[0m       0.6507        1.3068  116.3075\n",
      "     10        \u001b[36m1.2708\u001b[0m       0.6692        1.1951  117.5275\n",
      "Time taken:  1165.5719316005707  seconds\n"
     ]
    }
   ],
   "source": [
    "# 시간이 오래 걸리므로 10 epoch만 돌려보기로 함\n",
    "import time\n",
    "start_time = time.time()\n",
    "net = NeuralNetClassifier(\n",
    "    resnet,\n",
    "    max_epochs=10, lr=0.001, device='cuda', optimizer=torch.optim.Adam, batch_size=128, criterion=nn.CrossEntropyLoss, train_split=predefined_split(cifar100_dict['val']))\n",
    "net.fit(cifar100_dict['train'], y=None)\n",
    "end_time = time.time()\n",
    "print('Time taken: ', end_time-start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear probing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choiyj/.conda/envs/choi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(weights=models.ResNet18_Weights)\n",
    "resnet.fc = nn.Linear(512, 100)\n",
    "# mlp층을 제외하고는 freeze\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m3.4145\u001b[0m       \u001b[32m0.4231\u001b[0m        \u001b[35m2.3412\u001b[0m  86.8040\n",
      "      2        \u001b[36m2.7489\u001b[0m       \u001b[32m0.4628\u001b[0m        \u001b[35m2.0523\u001b[0m  86.8841\n",
      "      3        \u001b[36m2.6000\u001b[0m       \u001b[32m0.4850\u001b[0m        \u001b[35m1.9316\u001b[0m  87.2739\n",
      "      4        \u001b[36m2.5305\u001b[0m       \u001b[32m0.4937\u001b[0m        \u001b[35m1.8848\u001b[0m  87.0323\n",
      "      5        \u001b[36m2.5024\u001b[0m       \u001b[32m0.5028\u001b[0m        \u001b[35m1.8457\u001b[0m  87.1622\n",
      "      6        \u001b[36m2.4649\u001b[0m       \u001b[32m0.5075\u001b[0m        \u001b[35m1.8238\u001b[0m  87.0487\n",
      "      7        \u001b[36m2.4503\u001b[0m       \u001b[32m0.5117\u001b[0m        \u001b[35m1.7934\u001b[0m  87.4497\n",
      "      8        \u001b[36m2.4283\u001b[0m       \u001b[32m0.5159\u001b[0m        1.7960  87.1855\n",
      "      9        \u001b[36m2.4144\u001b[0m       0.5147        \u001b[35m1.7796\u001b[0m  87.2174\n",
      "     10        \u001b[36m2.4103\u001b[0m       \u001b[32m0.5189\u001b[0m        \u001b[35m1.7693\u001b[0m  87.7822\n",
      "Time taken:  871.9291796684265  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "net = NeuralNetClassifier(\n",
    "    resnet,\n",
    "    max_epochs=10, lr=0.001, device='cuda', optimizer=torch.optim.Adam, batch_size=128, criterion=nn.CrossEntropyLoss, train_split=predefined_split(cifar100_dict['val']))\n",
    "net.fit(cifar100_dict['train'], y=None)\n",
    "end_time = time.time()\n",
    "print('Time taken: ', end_time-start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSF-ADA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choiyj/.conda/envs/choi/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(weights=models.ResNet18_Weights)\n",
    "resnet.fc = nn.Linear(512, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssf-ada modules\n",
    "# nn.Module로 상속받아야\n",
    "class ssf_ada(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(torch.ones(dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(dim))\n",
    "        \n",
    "        nn.init.normal_(self.scale, mean=1, std=0.02)\n",
    "        nn.init.normal_(self.shift, mean=0, std=0.02)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert self.scale.shape == self.shift.shape\n",
    "        if x.shape[-1] == self.scale.shape[0]:\n",
    "            return x * self.scale + self.shift\n",
    "        elif x.shape[1] == self.scale.shape[0]:\n",
    "            return x * self.scale.view(1, -1, 1, 1) + self.shift.view(1, -1, 1, 1)\n",
    "        else:\n",
    "            raise ValueError('the input tensor shape does not match the shape of the scale factor.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssf-ada와 mlp층을 제외하고는 freeze\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in resnet.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# 간단하게 각 convolution layer와 block에만 ssf-ada를 적용\n",
    "resnet_finetune = nn.Sequential(resnet.conv1, ssf_ada(64),\n",
    "                                resnet.bn1, resnet.relu, resnet.maxpool, \n",
    "                                resnet.layer1, ssf_ada(64),\n",
    "                                resnet.layer2, ssf_ada(128),\n",
    "                                resnet.layer3, ssf_ada(256),\n",
    "                                resnet.layer4, ssf_ada(512),\n",
    "                                resnet.avgpool, nn.Flatten(), resnet.fc)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss       dur\n",
      "-------  ------------  -----------  ------------  --------\n",
      "      1        \u001b[36m3.2592\u001b[0m       \u001b[32m0.4780\u001b[0m        \u001b[35m1.9853\u001b[0m  110.0639\n",
      "      2        \u001b[36m2.4548\u001b[0m       \u001b[32m0.5469\u001b[0m        \u001b[35m1.6360\u001b[0m  110.2602\n",
      "      3        \u001b[36m2.2584\u001b[0m       \u001b[32m0.5751\u001b[0m        \u001b[35m1.5020\u001b[0m  109.8013\n",
      "      4        \u001b[36m2.1578\u001b[0m       \u001b[32m0.5755\u001b[0m        1.5063  110.4893\n",
      "      5        \u001b[36m2.1076\u001b[0m       \u001b[32m0.6093\u001b[0m        \u001b[35m1.3811\u001b[0m  111.5079\n",
      "      6        \u001b[36m2.0797\u001b[0m       \u001b[32m0.6103\u001b[0m        \u001b[35m1.3678\u001b[0m  111.4631\n",
      "      7        \u001b[36m2.0411\u001b[0m       0.5636        1.5740  111.4723\n",
      "      8        \u001b[36m2.0273\u001b[0m       0.5683        1.5622  111.2941\n",
      "      9        \u001b[36m1.9988\u001b[0m       \u001b[32m0.6114\u001b[0m        1.3827  111.5658\n",
      "     10        \u001b[36m1.9799\u001b[0m       \u001b[32m0.6247\u001b[0m        \u001b[35m1.3355\u001b[0m  110.0025\n",
      "Time taken:  1108.0351128578186  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "net = NeuralNetClassifier(\n",
    "    resnet_finetune,\n",
    "    max_epochs=10, lr=0.001, device='cuda', optimizer=torch.optim.Adam, batch_size=128, criterion=nn.CrossEntropyLoss, train_split=predefined_split(cifar100_dict['val']))\n",
    "net.fit(cifar100_dict['train'], y=None)\n",
    "end_time = time.time()\n",
    "print('Time taken: ', end_time-start_time, ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.scale\n",
      "1.shift\n",
      "6.scale\n",
      "6.shift\n",
      "8.scale\n",
      "8.shift\n",
      "10.scale\n",
      "10.shift\n",
      "12.scale\n",
      "12.shift\n",
      "15.weight\n",
      "15.bias\n"
     ]
    }
   ],
   "source": [
    "# activated parameters\n",
    "for name, param in resnet_finetune.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시간 자체는 큰 차이가 나지 않지만 훈련시키는 파라미터의 수는 압도적으로 적음\n",
    "- 좀 더 정확한 실험을 위해서는 epoch을 늘려볼 필요가 있음"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "choi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
