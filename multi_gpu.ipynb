{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version :  3.8.13 (default, Oct 21 2022, 23:50:54) \n",
      "[GCC 11.2.0]\n",
      "torch version :  1.13.0+cu117\n",
      "torchvision version :  0.14.0+cu117\n",
      "device number :  4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from source import functions\n",
    "from source import cifar_dataloader\n",
    "\n",
    "\n",
    "print('python version : ', sys.version)\n",
    "print('torch version : ', torch.__version__)\n",
    "print('torchvision version : ', torchvision.__version__)\n",
    "print('device number : ', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.DataPararell로 병렬처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage = 4\n",
    "multiple_gpus = [torch.device(f'cuda:{i}') for i in range(torch.cuda.device_count())]\n",
    "devices = multiple_gpus[:4]\n",
    "device_0 = devices[0]\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,input_size = functions.get_model('resnet', pretrained=True, transfer=True, feature_extract=False, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "path = './../data/'\n",
    "dataloaders_dict = cifar_dataloader.get_cifar10_dataloader(path, input_size, 16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "num_epochs = 5\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices = [device(type='cuda', index=0), device(type='cuda', index=1), device(type='cuda', index=2), device(type='cuda', index=3)],\n",
      "device_0 = cuda:0,\n",
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "print(f'devices = {devices},\\ndevice_0 = {device_0},\\ndevice = {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단일 gpu 사용\n",
    "# model = model.to(device_0)\n",
    "\n",
    "# multi-gpu 사용\n",
    "model = nn.DataParallel(model, device_ids=devices)\n",
    "# model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "train Loss: 0.9103 Acc: 0.7013\n",
      "val Loss: 0.3108 Acc: 0.8978\n",
      "Epoch 1/4\n",
      "train Loss: 0.8249 Acc: 0.7335\n",
      "val Loss: 0.2944 Acc: 0.9048\n",
      "Epoch 2/4\n",
      "train Loss: 0.7672 Acc: 0.7514\n",
      "val Loss: 0.2693 Acc: 0.9132\n",
      "Epoch 3/4\n",
      "train Loss: 0.7216 Acc: 0.7658\n",
      "val Loss: 0.2526 Acc: 0.9147\n",
      "Epoch 4/4\n",
      "train Loss: 0.6928 Acc: 0.7744\n",
      "val Loss: 0.2300 Acc: 0.9258\n"
     ]
    }
   ],
   "source": [
    "# model은 nn.DataParallel로 감싸져 있음\n",
    "# 데이터를 받는 device는 \"cuda\"\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()  \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in dataloaders_dict[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataloaders_dict[phase].dataset)\n",
    "        epoch_acc = running_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('choi': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1f1ea343d18a0e98dbd50f4a3341f5f39bd7be7d912eea72d8401c1237c2e901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
